{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GOOGLE_APPLICATION_CREDENTIALS=fastrune2178119551f6a51184.json\n"
     ]
    }
   ],
   "source": [
    "# HIDDEN\n",
    "%env GOOGLE_APPLICATION_CREDENTIALS=fastrune2178119551f6a51184.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tf_gpu2/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# HIDDEN\n",
    "# IMPORT\n",
    "%matplotlib inline\n",
    "import csv\n",
    "import os\n",
    "from operator import itemgetter, attrgetter, methodcaller\n",
    "from skimage.filters import threshold_otsu, threshold_adaptive, rank\n",
    "from skimage.morphology import disk\n",
    "from skimage.feature import match_template\n",
    "from skimage.color import lab2rgb\n",
    "from skimage.io import imread as sk_imread\n",
    "import matplotlib.image as img\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "from PIL import ImageDraw, ImageFont\n",
    "import PIL.Image as PILImage\n",
    "from scipy import ndimage\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import Image\n",
    "from IPython import display\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Imports the Google Cloud client library\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "# UTILITY func\n",
    "CUBE_SIZE = 250\n",
    "EDGE_GAP = 50\n",
    "HORIZ_TOLERANCE_FACTOR = 50\n",
    "VERT_TOLERANCE_FACTOR = 75\n",
    "cube_size = 250\n",
    "less_than_half_cube = 122\n",
    "minikube_size = cube_size - (less_than_half_cube * 2)\n",
    "\n",
    "bucket_name = \"thesis-papyri\"\n",
    "imgs_root = \"PAPYRI/\" # \"/Volumes/250GB/PAPYRI/\"\n",
    "cropped_root = \"/cropped2/\" # \"/Volumes/250gb/cropped2\"\n",
    "matched_root = \"/matched593/\" # \"/Volumes/250gb/cropped2\"\n",
    "local_temp_root = \"conda-bld/\"\n",
    "match_path = \"matched593_20190105/\"\n",
    "\n",
    "# Instantiates a client\n",
    "storage_client = storage.Client()\n",
    "\n",
    "def list_blobs_with_prefix(prefix):\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blobs = bucket.list_blobs(prefix=prefix, delimiter='/')\n",
    "\n",
    "    for blob in blobs:\n",
    "        if blob.name[-1] != '/':\n",
    "            yield blob.name\n",
    "        \n",
    "    #     if delimiter:\n",
    "    #         print('Prefixes:')\n",
    "    #         for prefix in blobs.prefixes:\n",
    "    #             print(prefix)\n",
    "\n",
    "def download_blob(source_blob_name, destination_file_name):\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "\n",
    "    blob.download_to_filename(destination_file_name)\n",
    "\n",
    "    print('Blob {} downloaded to {}.'.format(\n",
    "        source_blob_name,\n",
    "        destination_file_name))\n",
    "\n",
    "def gcp_img_read(img_path):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    fname = img_path[img_path.rfind(\"/\") + 1:]\n",
    "    download_blob(img_path, local_temp_root + fname)\n",
    "    result = img.imread(local_temp_root + fname)\n",
    "    os.remove(local_temp_root + fname)\n",
    "    return result\n",
    "\n",
    "def gcp_np_load(img_path):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    fname = img_path[img_path.rfind(\"/\") + 1:]\n",
    "    download_blob(img_path, local_temp_root + fname)\n",
    "    result = np.load(local_temp_root + fname)\n",
    "    os.remove(local_temp_root + fname)\n",
    "    return result\n",
    "    \n",
    "# Simple crop by x/y ranges\n",
    "def crop(image, ymin, ymax, xmin, xmax):\n",
    "    return image[ymin:ymax, xmin:xmax]\n",
    "\n",
    "\n",
    "def calc_combined_coordinates(base_x, base_y, offset_x, offset_y, base_rotate, base_x_end):\n",
    "    if base_rotate:\n",
    "        result_x = base_x_end - cube_size - offset_y # 250==CUBE_SIZE\n",
    "        result_y = base_y + offset_x\n",
    "    else:\n",
    "        result_x = base_x + offset_x\n",
    "        result_y = base_y + offset_y\n",
    "    return result_x, result_y\n",
    "\n",
    "def load_img_for_name(file_name):\n",
    "    img_path = \"\"\n",
    "    if \"-\" in file_name:\n",
    "        name_parts = file_name.split(\"-\")\n",
    "        unique_part = name_parts[0] + \"-\" + name_parts[1] + \"-\" + name_parts[2]\n",
    "        img_path = imgs_root + name_parts[0] + \"/\" + \\\n",
    "            unique_part + \"/\"\n",
    "    else:\n",
    "        img_path = imgs_root + file_name[0:4] + \"/\" + \\\n",
    "            file_name[0:4] + \"-\" + file_name[4:9] + \"-V/\"\n",
    "    \n",
    "    for file_ in list_blobs_with_prefix(img_path):\n",
    "        if (\" _018\" in file_):        \n",
    "            return gcp_img_read(file_) # img.imread(img_path + file_)\n",
    "\n",
    "def load_cropped_for_name(file_name):\n",
    "    img_path = cropped_root + \"/\" + file_name + \" _018.jpg.npy\"\n",
    "    return gcp_np_load(img_path) # np.load(img_path)\n",
    "\n",
    "def load_front_for_name(file_name):\n",
    "    img_path = \"\"\n",
    "    if \"-\" in file_name:\n",
    "        front_file_name = file_name.replace(\"-V-\",\"-R-\")\n",
    "        name_parts = front_file_name.split(\"-\")\n",
    "        unique_part = name_parts[0] + \"-\" + name_parts[1] + \"-\" + name_parts[2]\n",
    "        img_path = imgs_root + name_parts[0] + \"/\" + \\\n",
    "            unique_part + \"/\"\n",
    "    else:\n",
    "        img_path = imgs_root + file_name[0:4] + \"/\" + \\\n",
    "            file_name[0:4] + \"-\" + file_name[4:9] + \"-R/\"\n",
    "    #import pdb; pdb.set_trace()\n",
    "    #for root, dirs, files in os.walk(img_path):\n",
    "    for file_ in list_blobs_with_prefix(img_path):\n",
    "        if (\" _018\" in file_):        \n",
    "            return gcp_img_read(file_) # img.imread(img_path + file_)\n",
    "    \n",
    "# Pre-process the validation set\n",
    "def folder_walker(path, full_path, filter_text=\"\"):\n",
    "    result = []\n",
    "    #for root, dirs, files in os.walk(img_path):\n",
    "    for file_ in list_blobs_with_prefix(path):\n",
    "        if \"-V-\" in file_ and not file_.startswith(\".\"):\n",
    "            if (filter_text == \"\" or filter_text in file_):\n",
    "                result.append(file_)\n",
    "    return result\n",
    "\n",
    "no_rotate_raw = folder_walker(\"no_rotate/\", False)\n",
    "no_rotate = []\n",
    "for file_ in no_rotate_raw:\n",
    "    file_ = file_[file_.rfind('/')+1:]\n",
    "    split = file_.split(\"-\")\n",
    "    no_rotate.append(split[0]+split[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "# UTIL 2\n",
    "def find_match(big_img, small_img):\n",
    "    match_map = match_template(big_img, small_img)\n",
    "    offsets_arr = np.unravel_index(np.argmax(match_map), match_map.shape)\n",
    "    offset_x, offset_y = offsets_arr[::-1]        \n",
    "    return offset_x, offset_y, match_map[offsets_arr]\n",
    "  \n",
    "\n",
    "def extract_image_derivatives(file_name):\n",
    "    image = load_img_for_name(file_name)\n",
    "    split = file_name.split(\"-\")\n",
    "    short_name = split[0] + split[1]\n",
    "    img_crop = crops[short_name]\n",
    "    cropped = crop(image, img_crop['y_start']-cube_size, img_crop['y_end']+cube_size, \\\n",
    "                   img_crop['x_start']-cube_size, img_crop['x_end']+cube_size)\n",
    "    front = load_front_for_name(file_name)\n",
    "    front_adaptive = threshold_adaptive(front, 251, offset=5)  \n",
    "    # import pdb; pdb.set_trace()\n",
    "    cropped_adaptive = threshold_adaptive(cropped, 251, offset=5)\n",
    "    cropped_flipped_lr = cropped_adaptive[:,::-1]\n",
    "    offset_x_lr, offset_y_lr, val_lr = find_match(front_adaptive, cropped_flipped_lr)\n",
    "    cropped_flipped_ud = cropped_adaptive[:,::-1]\n",
    "    offset_x_ud, offset_y_ud, val_ud = find_match(front_adaptive, cropped_flipped_ud)\n",
    "\n",
    "    if (val_lr > val_ud):\n",
    "        return cropped_flipped_lr.shape[1], offset_x_lr, offset_y_lr\n",
    "    else:\n",
    "        return cropped_flipped_ud.shape[1], offset_x_ud, offset_y_ud\n",
    "    \n",
    "\n",
    "def extract_image_derivatives_orig(file_name):\n",
    "    image = load_img_for_name(file_name)\n",
    "    split = file_name.split(\"-\")\n",
    "    short_name = split[0] + split[1]\n",
    "    img_crop = crops[short_name]\n",
    "    cropped = crop(image, img_crop['y_start']-cube_size, img_crop['y_end']+cube_size, \\\n",
    "                   img_crop['x_start']-cube_size, img_crop['x_end']+cube_size)\n",
    "    front = load_front_for_name(file_name)\n",
    "    front_adaptive = threshold_adaptive(front, 251, offset=5)  \n",
    "    \n",
    "    cropped_adaptive = threshold_adaptive(cropped, 251, offset=5)\n",
    "    cropped_flipped_lr = cropped_adaptive[:,::-1]\n",
    "    offset_x_lr, offset_y_lr, val_lr = find_match(front_adaptive, cropped_flipped_lr)\n",
    "    cropped_flipped_ud = cropped_adaptive[:,::-1]\n",
    "    offset_x_ud, offset_y_ud, val_ud = find_match(front_adaptive, cropped_flipped_ud)\n",
    "\n",
    "    if (val_lr > val_ud):\n",
    "        return front, cropped_flipped_lr, offset_x_lr, offset_y_lr\n",
    "    else:\n",
    "        return front, cropped_flipped_ud, offset_x_ud, offset_y_ud\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def get_cube_coordinates(file_name, cropped_width, offset_x, offset_y, horizontal_flip, cubex, cubey):\n",
    "    #import pdb; pdb.set_trace()\n",
    "    if file_name not in no_rotate:\n",
    "        temp = cubex\n",
    "        cubex = cropped_width - cubey - cube_size\n",
    "        cubey = temp\n",
    "\n",
    "    # Next block is correcting the fact that the match between verso and recto is done with some edge\n",
    "    # on the verso fragment - so we add cube_size all sides - hence we have to reduce them here\n",
    "    # when applying the coordinates of the cubes\n",
    "    cropped_width -= (cube_size * 2)\n",
    "    offset_x += cube_size\n",
    "    offset_y += cube_size\n",
    "    \n",
    "    # The (-cube_size) is used in order to draw the cubes on the correct spot since the flipping\n",
    "    # of the fragments essentially means that the start point of the drawing is backwards \n",
    "    # either on x-axis or on y-axis - depending on whether this is a horizontal flip or not\n",
    "                    # (-cube_size if horizontal_flip else 0) + \\\n",
    "    reverse_cubex = -cube_size + \\\n",
    "        offset_x + cube_size + (cropped_width - cubex - cube_size)\n",
    "                    # (-cube_size if not horizontal_flip else 0) + \\\n",
    "    reverse_cubey = -cube_size + \\\n",
    "        offset_y + cube_size + cubey\n",
    "    \n",
    "    return reverse_cubex, reverse_cubey, reverse_cubex - offset_x, reverse_cubey - offset_y\n",
    "\n",
    "def get_cropped(image, file_name, cropped_width, offset_x, offset_y, horizontal_flip):\n",
    "    img_crop = crops[file_name]\n",
    "    img_width = img_crop['x_end'] - img_crop['x_start']\n",
    "    img_height = img_crop['y_end'] - img_crop['y_start']\n",
    "    cropped = crop(image, offset_y+cube_size, offset_y+img_height+cube_size, offset_x+cube_size, offset_x+img_width+cube_size)\n",
    "    return cropped\n",
    "\n",
    "def get_cropped_rudimentary(image, file_name):\n",
    "    # import pdb; pdb.set_trace()\n",
    "    short_name = file_name\n",
    "    if \"-\" in file_name:\n",
    "        short_name = file_name.split(\"-\")\n",
    "        short_name = short_name[0] + short_name[1]\n",
    "    \n",
    "    # We are using here the crop measurements of the back side in order to crop the front side - this is bad!!\n",
    "    img_crop = crops[short_name]\n",
    "    \n",
    "    cropped = crop(image, img_crop['y_start']-cube_size, img_crop['y_end']+cube_size, \\\n",
    "                   img_crop['x_start']-cube_size, img_crop['x_end']+cube_size)\n",
    "    return cropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "# READ crops\n",
    "crops = {}\n",
    "with open('crops.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, fieldnames=(\"file\",\"x_start\",\"y_start\",\"x_end\",\"y_end\",\"rotate\"))\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        row['name'] = row['file'].split(\"/\")[5] # stay with the folder name\n",
    "        row['name'] = row['name'].split(\"-\")\n",
    "        row['name'] = row['name'][0] + row['name'][1] # set the short name...\n",
    "        row['x_start'] = int(row['x_start'])\n",
    "        row['y_start'] = int(row['y_start'])\n",
    "        row['x_end'] = int(row['x_end'])\n",
    "        row['y_end'] = int(row['y_end'])\n",
    "        # import pdb; pdb.set_trace()\n",
    "        row['rotate'] = True if row['rotate'] == 'True' else False\n",
    "        crops[row['name']] = row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "# READ matches\n",
    "matches = {}\n",
    "with open('20190105_120300_pairs_final.csv') as csvfile: # cubes_X3\n",
    "    reader = csv.DictReader(csvfile, fieldnames=(\"fragmentAndSide\", \n",
    "                        \"fragment\", \n",
    "                        \"fragmentTotal\",\n",
    "                        \"fragmentVote\",\n",
    "                        \"devideVoteByTotal\",\n",
    "                        \"fragmentAndSideTotal\",\n",
    "                        \"fragmentAndSideVote\",\n",
    "                        \"devideSideVoteBySideTotal\",\n",
    "                        \"fragmentAndSideTrendVote\",\n",
    "                        \"devideSideTrendVoteBySideTotal\",\n",
    "                        \"fragmentAndSideTrendVoteStrict\",\n",
    "                        \"devideSideTrendVoteStrictBySideTotal\",\n",
    "                        \"fragmentAndSideTrendVoteSync\",\n",
    "                        \"devideSideTrendVoteSyncBySideTotal\",\n",
    "                        \"firstFileName\",\n",
    "                        \"firstCroppedWidth\",\n",
    "                        \"firstOffsetX\",\n",
    "                        \"firstOffsetY\",\n",
    "                        \"firstHorizontalFlip\",\n",
    "                        \"secondFileName\",\n",
    "                        \"secondCroppedWidth\",\n",
    "                        \"secondOffsetX\",\n",
    "                        \"secondOffsetY\",\n",
    "                        \"secondHorizontalFlip\",\n",
    "                        \"fragmentAndSideTrend\",\n",
    "                        \"rotateFragmentAndSideCubes\",\n",
    "                        \"rotateFragmentAndSideDrawRect\",\n",
    "                        \"rotateFragmentAndSideMatchPoint\",\n",
    "                        \"origCoordinates\",\n",
    "                        \"class\",\n",
    "                        \"votesOverlapMax\",\n",
    "                        \"divideOverlapMaxBySideTotal\",\n",
    "                        \"votesOverlapHeight\",\n",
    "                        \"votesSupportOverlapRect\",\n",
    "                        \"divideSupportOverlapBySideTotal\",\n",
    "                        \"divideSupportOverlapBySideVote\",\n",
    "                        \"fragmentAndSideCubes\",\n",
    "                        \"fragmentAndSideDrawRect\",\n",
    "                        \"fragmentAndSideMatchPoint\"\n",
    "                                                ))\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        matches[row[\"fragmentAndSide\"]] = row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "# Based on code from 18_alignment\n",
    "def draw_match_front(df_row, firstImg, secondImg):\n",
    "    rectanglesArr = eval(df_row[\"fragmentAndSideDrawRect\"])\n",
    "    if len(rectanglesArr) > 0:\n",
    "        firstRotate = (df_row[\"fragmentAndSide\"][df_row[\"fragmentAndSide\"].rfind(\"P\")-2] == \"0\")\n",
    "        secondRotate = (df_row[\"fragmentAndSide\"][-1] == \"1\")\n",
    "\n",
    "        # rotate the images if needed\n",
    "        firstFrontRotate = False\n",
    "        secondFrontRotate = False        \n",
    "        if not firstRotate and df_row[\"firstHorizontalFlip\"] == '1':\n",
    "            firstImg = np.rot90(firstImg, 2) # firstImg.rotate(180)\n",
    "            firstFrontRotate = True\n",
    "        if not secondRotate and df_row[\"secondHorizontalFlip\"] == '1':\n",
    "            secondImg = np.rot90(secondImg, 2) # secondImg.rotate(180)\n",
    "            secondFrontRotate = True        \n",
    "        cubesArr = eval(df_row[\"fragmentAndSideCubes\"])\n",
    "        pointsArr = eval(df_row[\"fragmentAndSideMatchPoint\"])\n",
    "\n",
    "        # correct the cubes, rects and points incase we had a rotation\n",
    "        # import pdb; pdb.set_trace()\n",
    "        for cube, rect, point in zip(cubesArr, rectanglesArr, pointsArr):\n",
    "            if not firstRotate:\n",
    "                cube[0] = firstImg.shape[1] - cube[0] - cube_size # reduce cube_size cause we measure from top left corner of the cube\n",
    "                cube[1] = firstImg.shape[0] - cube[1] - cube_size # reduce cube_size - see above\n",
    "                rect[0] = cube[0] + cube_size + EDGE_GAP - HORIZ_TOLERANCE_FACTOR\n",
    "                rect[2] = cube[0] + cube_size + EDGE_GAP + HORIZ_TOLERANCE_FACTOR\n",
    "                point[0] = cube[0] + cube_size + EDGE_GAP\n",
    "            if not secondRotate:\n",
    "                cube[2] = secondImg.shape[1] - cube[2] - cube_size # reduce cube_size - see above\n",
    "                cube[3] = secondImg.shape[0] - cube[3] - cube_size # reduce cube_size - see above\n",
    "            if not firstRotate or not secondRotate:\n",
    "                rect[1] = cube[1] - cube[3] - VERT_TOLERANCE_FACTOR\n",
    "                rect[3] = cube[1] - cube[3] + VERT_TOLERANCE_FACTOR\n",
    "                point[1] = cube[1] - cube[3]\n",
    "                \n",
    "        # rectanglesArr contains the projections of the matched position as they are reflected by each pair\n",
    "        # In this block we set the size for the overlap slate\n",
    "        mins = np.amin(rectanglesArr, 0)\n",
    "        maxs = np.amax(rectanglesArr, 0)\n",
    "        minsmaxs = [mins[0], mins[1], maxs[2], maxs[3]]\n",
    "        minsmins = [mins[0], mins[1], mins[0], mins[1]]\n",
    "        width = maxs[2] - mins[0]\n",
    "        height = maxs[3] - mins[1]\n",
    "        slate = np.zeros((width, height))\n",
    "\n",
    "        # Now we iterate over the matched pair and add each match rectangle to the overlap count on the slate\n",
    "        for rect in rectanglesArr:\n",
    "            rect_slide = np.zeros((width, height))\n",
    "            rect_adjusted =  np.subtract(rect, minsmins)\n",
    "            rect_slide[rect_adjusted[0]:rect_adjusted[2], rect_adjusted[1]:rect_adjusted[3]] = 1\n",
    "            slate = slate + rect_slide\n",
    "\n",
    "        # Then we determine what's the max overlap that we observe and keep it and its size and derivative in the df\n",
    "        # so we will use it later for the 2nd phase classification algorithm\n",
    "        slate_max = np.amax(slate)\n",
    "        max_indices = np.where(slate == slate_max)\n",
    "    \n",
    "        # Now we create a binary mask from the overlap max projection\n",
    "        slate_mask = np.copy(slate)\n",
    "        slate_mask[slate_mask < slate_max] = 0\n",
    "        slate_mask[slate_mask == slate_max] = 1\n",
    "        slate_mask_size = float(len(np.where(slate_mask == 1)[0]))\n",
    "\n",
    "        # Calculate per each match pair what is the overlap of their projection with the mask of the max overlap\n",
    "        overlaps_percent_arr = []\n",
    "        for rect in rectanglesArr:\n",
    "            rect_slide = np.zeros((width, height))\n",
    "            rect_adjusted =  np.subtract(rect, minsmins)\n",
    "            rect_slide[rect_adjusted[0]:rect_adjusted[2], rect_adjusted[1]:rect_adjusted[3]] = 1\n",
    "            overlap_indices = np.where((rect_slide == slate_mask) & (rect_slide == 1))\n",
    "            overlaps_percent_arr.append(float(len(overlap_indices[0]))/slate_mask_size)\n",
    "\n",
    "        # We'll now use the mid-point of the max-overlap rectangle (based on the saved indices) in order to \n",
    "        # place and align the fragments\n",
    "        # FIXME: need to fix next line as the square might be a jigsaw - need to pick the overall min and max indices\n",
    "        voted_square = [max_indices[0][0], max_indices[1][0], max_indices[0][-1]+1, max_indices[1][-1]+1]\n",
    "        adjusted_vote = np.add(minsmins,voted_square)\n",
    "        mid_point = [(adjusted_vote[0] + adjusted_vote[2])/2, (adjusted_vote[1] + adjusted_vote[3])/2]\n",
    "        \n",
    "        # We prepare the measurements of the connected image\n",
    "        # import pdb; pdb.set_trace()\n",
    "        con_width = firstImg.shape[1] + secondImg.shape[1]\n",
    "        con_height = 0\n",
    "        first_offset = (-adjusted_vote[1]) if adjusted_vote[1] < 0 else 0\n",
    "        second_offset = int(mid_point[1] + first_offset)\n",
    "        adjusted_vote[1] += first_offset\n",
    "        adjusted_vote[3] += first_offset\n",
    "        con_height = int(np.maximum(firstImg.shape[0] + first_offset, secondImg.shape[0] + second_offset))\n",
    "\n",
    "        # We paste the 2 images into the connected image in the correct offsets\n",
    "        conImage = PILImage.new('RGBA', (con_width, con_height))\n",
    "        conImage.paste(PILImage.fromarray(firstImg), (0, first_offset))\n",
    "        conImage.paste(PILImage.fromarray(secondImg), (firstImg.shape[1]+1, second_offset))\n",
    "\n",
    "        # Draw the image and draw the max overlap rectangle\n",
    "        draw = ImageDraw.Draw(conImage)\n",
    "\n",
    "        # Draw the lines from one image to the other based on the cubes\n",
    "        cubeMid = CUBE_SIZE / 2\n",
    "        for overlap_percent, cube_pair in zip(overlaps_percent_arr, cubesArr):\n",
    "            color=\"\"\n",
    "            lwidth=1\n",
    "            if (overlap_percent < 0.1):\n",
    "                color=\"red\"\n",
    "            elif (overlap_percent < 0.5):\n",
    "                color=\"yellow\"\n",
    "                lwidth=1\n",
    "            else:\n",
    "                color=\"green\"\n",
    "                lwidth=4\n",
    "            # import pdb; pdb.set_trace()\n",
    "            startLineX = ((cube_pair[0] + cubeMid) if False else (firstImg.shape[1] - cube_pair[0] - cubeMid))\n",
    "            endLineX = ((cube_pair[2] + cubeMid) if False else (secondImg.shape[1] - cube_pair[2] - cubeMid))\n",
    "            draw.line((startLineX , \\\n",
    "                       cube_pair[1] + cubeMid + first_offset, \\\n",
    "                       firstImg.shape[1] + 1 + endLineX, \\\n",
    "                       cube_pair[3] + cubeMid + second_offset), \\\n",
    "                      fill=color, width=lwidth)\n",
    "\n",
    "\n",
    "            \n",
    "        for root, dirs, files in os.walk(local_temp_root):\n",
    "            for f in files:\n",
    "                os.remove(local_temp_root + f)\n",
    "            \n",
    "        img_path = local_temp_root+\"R=\"+df_row[\"fragmentAndSide\"]+\".jpg\"\n",
    "        conImage.save(img_path)\n",
    "        return conImage, img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "# RUN\n",
    "loading = img.imread(\"loading.jpg\", format='jpg')\n",
    "def view_image(item):\n",
    "    # import pdb; pdb.set_trace()\n",
    "        \n",
    "    print(\"LOADING \"+ item[\"firstFileName\"])\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(loading, cmap=plt.cm.gray)\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    gridspec.GridSpec(9,2)\n",
    "    \n",
    "    first = load_front_for_name(item[\"firstFileName\"])\n",
    "    second = load_front_for_name(item[\"secondFileName\"])\n",
    "    \n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    \n",
    "    ax1 = plt.subplot2grid((13, 4), (12,0))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(first, cmap=plt.cm.gray)\n",
    "    \n",
    "    ax2 = plt.subplot2grid((13, 4), (12,2))\n",
    "    plt.axis('off')\n",
    "    plt.imshow(second, cmap=plt.cm.gray)\n",
    "\n",
    "    first_cropped = get_cropped(first, item[\"firstFileName\"], int(item[\"firstCroppedWidth\"]), int(item[\"firstOffsetX\"]), \\\n",
    "                                int(item[\"firstOffsetY\"]), (True if item[\"firstHorizontalFlip\"] == '1' else False))\n",
    "    ax3 = plt.subplot2grid((13, 4), (10,0), colspan=2, rowspan=2)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(first_cropped, cmap=plt.cm.gray)\n",
    "\n",
    "    second_cropped = get_cropped(second, item[\"secondFileName\"], int(item[\"secondCroppedWidth\"]), int(item[\"secondOffsetX\"]), \\\n",
    "                                 int(item[\"secondOffsetY\"]), (True if item[\"secondHorizontalFlip\"] == '1' else False))\n",
    "    ax4 = plt.subplot2grid((13, 4), (10,2), colspan=2, rowspan=2)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(second_cropped, cmap=plt.cm.gray)\n",
    "    \n",
    "    # draw the rectangles-centeres on the images\n",
    "    for cube_match in eval(item[\"fragmentAndSideCubes\"]):\n",
    "        x_co, y_co, x_mini_co, y_mini_co = \\\n",
    "            get_cube_coordinates(item[\"firstFileName\"], int(item[\"firstCroppedWidth\"]), \\\n",
    "                                 int(item[\"firstOffsetX\"]), int(item[\"firstOffsetY\"]), \\\n",
    "                                 (True if item[\"firstHorizontalFlip\"] == '1' else False), cube_match[0], cube_match[1])\n",
    "        x_co += less_than_half_cube\n",
    "        y_co += less_than_half_cube\n",
    "        rect = plt.Rectangle((x_co, y_co), minikube_size, minikube_size, edgecolor='r', facecolor='r')\n",
    "        ax1.add_patch(rect)    \n",
    "        x_mini_co += less_than_half_cube\n",
    "        y_mini_co += less_than_half_cube\n",
    "        rect = plt.Rectangle((x_mini_co, y_mini_co), minikube_size, minikube_size, edgecolor='r', facecolor='r')\n",
    "        ax3.add_patch(rect)    \n",
    "\n",
    "        \n",
    "        x_co, y_co, x_mini_co, y_mini_co = \\\n",
    "            get_cube_coordinates(item[\"secondFileName\"], int(item[\"secondCroppedWidth\"]), \\\n",
    "                                 int(item[\"secondOffsetX\"]), int(item[\"secondOffsetY\"]), \\\n",
    "                                 (True if item[\"secondHorizontalFlip\"] == '1' else False), cube_match[2], cube_match[3])\n",
    "        x_co += less_than_half_cube\n",
    "        y_co += less_than_half_cube\n",
    "        rect = plt.Rectangle((x_co, y_co), minikube_size, minikube_size, edgecolor='r', facecolor='r')\n",
    "        ax2.add_patch(rect)    \n",
    "        x_mini_co += less_than_half_cube\n",
    "        y_mini_co += less_than_half_cube\n",
    "        rect = plt.Rectangle((x_mini_co, y_mini_co), minikube_size, minikube_size, edgecolor='r', facecolor='r')\n",
    "        ax4.add_patch(rect)    \n",
    "\n",
    "    ax5 = plt.subplot2grid((13, 4), (0,0), colspan=4, rowspan=5)\n",
    "    plt.axis('off')\n",
    "    conn_front, img_path = draw_match_front(item, first_cropped, second_cropped)\n",
    "    plt.imshow(conn_front, cmap=plt.cm.gray)\n",
    "\n",
    "    matched_name = match_path + '0=' + item[\"fragmentAndSide\"] + '.jpg'\n",
    "    matched = gcp_img_read(matched_name)\n",
    "    ax6 = plt.subplot2grid((13, 4), (5,0), colspan=4, rowspan=5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(matched, cmap=plt.cm.gray)\n",
    "    matched_path = local_temp_root+'V=' + item[\"fragmentAndSide\"] + '.jpg'\n",
    "    print(matched_path)\n",
    "    plt.imsave(matched_path, matched)\n",
    "    \n",
    "    local_file = FileLink(img_path)\n",
    "    display.display(local_file)\n",
    "    local_file = FileLink(matched_path)\n",
    "    display.display(local_file)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3912ce80f79a4565ac729b5fc109a911",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='item', options={'P593Fg001_0_P593Fg002_0': OrderedDict([('fragmentâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.view_image>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HIDDEN\n",
    "widgets.interact(view_image, item=matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "widgets": {
   "state": {
    "c8d2ebd5008045d8bdf3ff30fc055e9a": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
